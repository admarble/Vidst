# OpenAI Whisper Configuration

# Model configuration
model:
  # Model size (tiny, base, small, medium, large-v1, large-v2, large-v3)
  size: "large-v3"
  # Use CUDA for acceleration if available
  use_cuda: true
  # Device to use (cpu, cuda, cuda:0, etc.)
  device: "cuda" if torch.cuda.is_available() else "cpu"
  # Download directory for model files
  download_root: "./.models/whisper"
  # Use 8-bit quantization to reduce memory usage
  use_int8: true
  # Use flash attention for faster inference
  use_flash_attention: true
  # Compute type for model
  compute_type: "float16"  # or float32

# Audio preprocessing
audio:
  # Sample rate for audio processing
  sample_rate: 16000
  # Enable voice activity detection to skip silence
  vad_enabled: true
  # VAD aggressiveness (0-3)
  vad_aggressiveness: 3
  # Chunk size in seconds for processing long audio
  chunk_size: 30
  # Chunk overlap in seconds
  chunk_overlap: 5
  # Normalize audio volume
  normalize_volume: true
  # High-pass filter cutoff frequency (Hz)
  high_pass_filter: 80
  # Low-pass filter cutoff frequency (Hz)
  low_pass_filter: 8000

# Transcription options
transcription:
  # Language code (en, fr, de, etc.) or "auto" for auto-detection
  language: "auto"
  # Task type: transcribe or translate
  task: "transcribe"
  # Whether to detect multiple speakers
  detect_speakers: true
  # Maximum number of speakers to detect
  max_speakers: 10
  # Enable word-level timestamps
  word_timestamps: true
  # Confidence threshold for word timestamps
  word_confidence_threshold: 0.5
  # Prompt to guide transcription
  initial_prompt: ""
  # Temperature for sampling
  temperature: 0
  # Enable word-level confidence scores
  compute_word_confidence: true

# Performance options
performance:
  # Enable caching of processed audio
  enable_caching: true
  # Cache directory
  cache_dir: "./.cache/whisper"
  # Number of CPU threads to use
  num_threads: 4
  # Number of worker processes
  num_workers: 2
  # Beam size for beam search decoding
  beam_size: 5

# Output formats
output:
  # Enable SRT subtitle output
  enable_srt: true
  # Enable VTT subtitle output
  enable_vtt: true
  # Enable JSON output
  enable_json: true
  # Include metadata in output
  include_metadata: true
  # Include speaker diarization in output
  include_speaker_diarization: true
